{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated user-product interaction data for different users\n",
    "# Each user has their own local dataset\n",
    "data_user1 = {\n",
    "    'Product1': [5],\n",
    "    'Product2': [4],\n",
    "    'Product3': [0],\n",
    "    'Product4': [0],\n",
    "}\n",
    "data_user2 = {\n",
    "    'Product1': [0],\n",
    "    'Product2': [0],\n",
    "    'Product3': [3],\n",
    "    'Product4': [4],\n",
    "}\n",
    "data_user3 = {\n",
    "    'Product1': [3],\n",
    "    'Product2': [5],\n",
    "    'Product3': [0],\n",
    "    'Product4': [0],\n",
    "}\n",
    "\n",
    "local_data = {\n",
    "    'User1': (data_user1),\n",
    "    'User2': (data_user2),\n",
    "    'User3': (data_user3),\n",
    "}\n",
    "\n",
    "# Initialize global model weights\n",
    "global_model = {\n",
    "    'Product1': 0.5,\n",
    "    'Product2': 0.5,\n",
    "    'Product3': 0.5,\n",
    "    'Product4': 0.5,\n",
    "}\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Set this to true, to run the attack\n",
    "should_attack = True\n",
    "\n",
    "# Variables used by the attack from the paper of Yin et al.\n",
    "# top-k\n",
    "k = 2\n",
    "# number of filler items\n",
    "f = 2\n",
    "\n",
    "# This is the product that we are targeting, at the end of the attack, the global model should promote this product more.\n",
    "target_name = \"Product4\"\n",
    "attack_factor = 2\n",
    "global_model_at_start_of_attack = None\n",
    "number_of_fake_users = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 - Global Model: {'Product1': np.float64(0.5233333333333333), 'Product2': np.float64(0.5266666666666666), 'Product3': np.float64(0.5083333333333333), 'Product4': np.float64(0.5116666666666667)}\n",
      "Round 2 - Global Model: {'Product1': np.float64(0.5465111111111111), 'Product2': np.float64(0.5531555555555555), 'Product3': np.float64(0.5166388888888889), 'Product4': np.float64(0.5232944444444445)}\n",
      "Round 3 - Global Model: {'Product1': np.float64(0.5695343703703704), 'Product2': np.float64(0.5794678518518518), 'Product3': np.float64(0.5249167592592593), 'Product4': np.float64(0.5348834629629631)}\n",
      "Round 4 - Global Model: {'Product1': np.float64(0.5924041412345679), 'Product2': np.float64(0.6056047328395061), 'Product3': np.float64(0.533167036728395), 'Product4': np.float64(0.5464338514197532)}\n",
      "Round 5 - Global Model: {'Product1': np.float64(0.6151214469596707), 'Product2': np.float64(0.6315673679539094), 'Product3': np.float64(0.5413898132726337), 'Product4': np.float64(0.5579457385816874)}\n",
      "Malicious model update created:  {'Product4': np.float64(0.1307973377502054), 'Product1': np.float64(0.0), 'Product2': np.float64(0.0), 'Product3': np.float64(0.0)}\n",
      "Round 6 - Global Model: {'Product1': np.float64(0.624792528539786), 'Product2': np.float64(0.6426200326168983), 'Product3': np.float64(0.5449021135393871), 'Product4': np.float64(0.6376042948124023)}\n",
      "Malicious model update created:  {'Product4': np.float64(0.005015737804495934), 'Product3': np.float64(0.003512300266753421), 'Product1': np.float64(0.009671081580115204), 'Product2': np.float64(0.0)}\n",
      "Round 7 - Global Model: {'Product1': np.float64(0.6399623107897381), 'Product2': np.float64(0.6536411182379929), 'Product3': np.float64(0.55041642495819), 'Product4': np.float64(0.645273853136668)}\n",
      "Malicious model update created:  {'Product4': np.float64(0.008367265101324906), 'Product3': np.float64(0.009026611685556296), 'Product2': np.float64(0.022073750284083427), 'Product1': np.float64(0.0)}\n",
      "Round 8 - Global Model: {'Product1': np.float64(0.649562418473196), 'Product2': np.float64(0.677244286633932), 'Product3': np.float64(0.5590738938857105), 'Product4': np.float64(0.6548476134043727)}\n",
      "Malicious model update created:  {'Product4': np.float64(0.022396673229559294), 'Product3': np.float64(0.017684080613076802), 'Product1': np.float64(0.03444097151352521), 'Product2': np.float64(0.0)}\n",
      "Round 9 - Global Model: {'Product1': np.float64(0.6788156524281441), 'Product2': np.float64(0.6881664458149779), 'Product3': np.float64(0.5726661201019176), 'Product4': np.float64(0.6724245015164003)}\n",
      "Malicious model update created:  {'Product4': np.float64(0.022133095210321363), 'Product3': np.float64(0.03127630682928395), 'Product2': np.float64(0.056599077861068436), 'Product1': np.float64(0.0)}\n",
      "Round 10 - Global Model: {'Product1': np.float64(0.6883047505640637), 'Product2': np.float64(0.7313997290332599), 'Product3': np.float64(0.5940059152613629), 'Product4': np.float64(0.6898256637772748)}\n",
      "Final Recommendations: [('Product2', np.float64(0.7313997290332599)), ('Product4', np.float64(0.6898256637772748))]\n"
     ]
    }
   ],
   "source": [
    "# Simulate local training\n",
    "def local_training(user_data, global_model):\n",
    "    local_model = global_model.copy()\n",
    "    for product, rating in user_data.items():\n",
    "        if rating[0] > 0:  # Only update for rated products\n",
    "            error = rating[0] - local_model[product]\n",
    "            local_model[product] = learning_rate * error\n",
    "        else:\n",
    "            local_model[product] = np.float64(0.0)\n",
    "    # print(\"LOCAL MODEL: \", local_model)\n",
    "    return local_model\n",
    "\n",
    "def attacker_training(global_model):\n",
    "    # Select 'k' most popular items\n",
    "    # Section 4.2.1 'Estimating Popular Items' from the paper from Yin et al.\n",
    "    item_embeds = list(map(lambda m: m[1], global_model.items()))\n",
    "    mean_item_feature = sum(item_embeds)/len(item_embeds)\n",
    "    \n",
    "    def in_prod(item):\n",
    "        return [item[0], item[1], item[1] * mean_item_feature]\n",
    "    \n",
    "    in_products = list(map(in_prod, global_model.items()))\n",
    "    \n",
    "    def sort_by_in_product(item):\n",
    "        return item[2]\n",
    "    k_popular = sorted(in_products, key=sort_by_in_product, reverse=True)[:k]\n",
    "\n",
    "    # Create target item embedding\n",
    "    # calculate mean distance from target item to k-popular items\n",
    "    # Section 4.2.2 'Constructing the targeted item embedding' from the paper from Yin et al.\n",
    "    def distance(a, b):\n",
    "        return abs(a-b)\n",
    "\n",
    "    target = global_model[target_name]\n",
    "    mean_dist = sum(map(lambda item: distance(item[1], target), k_popular))/len(k_popular)\n",
    "\n",
    "    # Calculate target embedding in the target model with factor 'lambda'\n",
    "    target = attack_factor * mean_dist + target\n",
    "    target_update = target - global_model[target_name]\n",
    "    \n",
    "    # Section 4.2.3 'Select filler items' from the paper from Yin et al.\n",
    "    def calc_dev_since_start(item):\n",
    "        return abs(item[1] - global_model_at_start_of_attack[item[0]])\n",
    "    \n",
    "    filler_deviations = list(map(lambda item: (item[0], calc_dev_since_start(item)), global_model.items()))\n",
    "    filler_deviations = sorted(filler_deviations, key=lambda item: item[1])\n",
    "    \n",
    "    filler_items = list(filter(lambda item: item[0] != target_name, filler_deviations[:f]))\n",
    "    # calculate model updat for filler items\n",
    "    filler_updates = [(item[0], global_model[item[0]] - global_model_at_start_of_attack[item[0]]) for item in filler_items]\n",
    "\n",
    "    # Section 4.2.4 'Sending the malicious model updates' from the paper from Yin et al.\n",
    "    malicious_model = {\n",
    "        target_name: target_update\n",
    "    }\n",
    "    \n",
    "    for item in filler_updates:\n",
    "        malicious_model[item[0]] = item[1]\n",
    "        \n",
    "    for key in global_model:\n",
    "        if key not in malicious_model.keys():\n",
    "            malicious_model[key] = np.float64(0.0)\n",
    "        \n",
    "    \n",
    "    print(\"Malicious model update created: \", malicious_model)\n",
    "    \n",
    "    return malicious_model\n",
    "    \n",
    "\n",
    "# Federated averaging\n",
    "def federated_averaging(local_models):\n",
    "    aggregated_model = global_model.copy()\n",
    "    for product in global_model.keys():\n",
    "        \n",
    "        aggregated_model[product] += np.mean([model[product] for model in local_models])\n",
    "    return aggregated_model\n",
    "\n",
    "# Perform federated learning rounds\n",
    "num_rounds = 10\n",
    "# Set the round number at which we start the attack.\n",
    "initial_round_of_attack = 5\n",
    "for round_num in range(num_rounds):\n",
    "    local_models = []\n",
    "    if (round_num == initial_round_of_attack and should_attack):\n",
    "        global_model_at_start_of_attack = global_model.copy()\n",
    "    if (round_num >= initial_round_of_attack and should_attack):\n",
    "        malicious_model = attacker_training(global_model)\n",
    "        # print(malicious_model)\n",
    "        for _ in range(number_of_fake_users):\n",
    "            local_models.append(malicious_model)\n",
    "    for user, user_data in local_data.items():\n",
    "        local_model = local_training(user_data, global_model)\n",
    "        # print(local_model)\n",
    "        local_models.append(local_model)\n",
    "    global_model = federated_averaging(local_models)\n",
    "    print(f\"Round {round_num + 1} - Global Model: {global_model}\")\n",
    "\n",
    "# Recommend products for a new user based on the global model\n",
    "def recommend_products(global_model, top_n=2):\n",
    "    recommendations = sorted(global_model.items(), key=lambda x: x[1], reverse=True)\n",
    "    return recommendations[:top_n]\n",
    "\n",
    "# Example usage\n",
    "recommendations = recommend_products(global_model)\n",
    "print(f\"Final Recommendations: {recommendations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round 10 - Global Model: {'Product1': np.float64(0.7326813609434842), 'Product2': np.float64(0.7416779381571845), 'Product3': np.float64(0.5915892208860152), 'Product4': np.float64(0.6796171415129091)} labmda 1.14\n",
    "# Round 10 - Global Model: {'Product1': np.float64(0.7264563374764591), 'Product2': np.float64(0.758807242830239), 'Product3': np.float64(0.58209437988817), 'Product4': np.float64(0.6149321318434384)}\n",
    "# Round 10 - Global Model: {'Product1': np.float64(0.7326813609434842), 'Product2': np.float64(0.7416779381571845), 'Product3': np.float64(0.5915892208860152), 'Product4': np.float64(0.6852875811546333)} lambda 1.3\n",
    "\n",
    "# Round 10 - Global Model: {'Product1': np.float64(0.7058974854138137), 'Product2': np.float64(0.7501068731152054), 'Product3': np.float64(0.5950089337089313), 'Product4': np.float64(0.701647777562632)} 2 fake users\n",
    "# Round 10 - Global Model: {'Product1': np.float64(0.7326813609434842), 'Product2': np.float64(0.7416779381571845), 'Product3': np.float64(0.5915892208860152), 'Product4': np.float64(0.7016771880717245)} 1 fake user\n",
    "# Round 10 - Global Model: {'Product1': np.float64(0.6883047505640637), 'Product2': np.float64(0.7313997290332599), 'Product3': np.float64(0.5940059152613629), 'Product4': np.float64(0.6898256637772748)} 4 fake users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
